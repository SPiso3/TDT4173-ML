{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[120]Magna Graecia\\\n",
    "Sergio Enrico Pisoni 132855\\\n",
    "Sofia Papaioannou 132898\\\n",
    "Lefteris Verouchis 132873"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Search domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Check if the data is intuitive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand how the data was generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Explore individual features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Explore pairs and groups of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Models experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of our initial experiments, we considered using Random Forest for both latitude and longitude prediction. Random Forest is a robust ensemble learning method that often performs well for regression tasks. \n",
    "\n",
    "We set the number of trees to be 20 with maximum depth dor each tree to be 25 for lattitude and 35 for lontitude, since we wanted to capture complex relationships in the data but not have the fear of overfitting. \n",
    "\n",
    "After training the models, we evaluated their performance using the Mean Absolute Error (MAE) metric. While Random Forest yielded reasonable results for first try and without compliting all the feature engineering that we added in the process, we observed that training times were relatively slow, especially with the large dataset and higher number of trees used in the ensemble.\n",
    "\n",
    "So despite the effectiveness of Random Forest, we decided to explore XGBOOST due to lower training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model for latitude prediction\n",
    "model_lat = RandomForestRegressor(n_estimators=20, max_depth=25, random_state=42, verbose=3)\n",
    "model_lat.fit(X_train_lat, y_train_lat)\n",
    "\n",
    "# Train Random Forest model for longitude prediction\n",
    "model_lon = RandomForestRegressor(n_estimators=20, max_depth=35, random_state=42, verbose=3)\n",
    "model_lon.fit(X_train_lon, y_train_lon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Feature engineering is a critical step in preparing data for meaningful analysis and predictive modeling, especially when dealing with complex datasets like AIS (Automatic Identification System). AIS data records extensive information on vessel locations, speeds, directions, navigational statuses,schedules and ports characteristics but it also comes with inherent challenges such as placeholder values, outliers, and inconsistent formats.\n",
    "\n",
    "In this project, we used feature engineering to transform raw AIS and port data into a more accurate, comprehensive dataset. The goal was to enhance the quality and relevance of the data by refining existing features and creating new ones, making the information more suitable for understanding vessel behaviors, predicting arrival times, and optimizing routes and get more accurate predictions. By addressing missing values, aligning timestamps, and creating meaningful flags and derived features, we tried to take advantage from the most useful attributes.\n",
    "\n",
    "In this section we document the specific steps taken, the rationale behind each transformation,in order to succeed it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "-> Cleaning Ports Data: To streamline analysis, we removed unnecessary columns from the ports data, such as name, portLocation, UN_LOCODE, countryName, and ISO. We kept only the attributes that we considered essential and were important to give in order to train our model and get better results (portId, latitude, longitude). This reduced data size and minimized potential redundancies.\n",
    "<br>-> Renaming Columns: We renamed latitude and longitude in the ports dataset to port_latitude and port_longitude. This renaming prevented confusion with vessel latitude and longitude values, making the dataset more intuitive and easier to work with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports = pd.read_csv('ports.csv', sep ='|')\n",
    "# Clean port data\n",
    "ports = ports.drop(columns=['name', 'portLocation', 'UN_LOCODE', 'countryName', 'ISO'], errors='ignore')\n",
    "# Rename latitude and longitude to distinguish them\n",
    "ports = ports.rename(columns={\n",
    "    'latitude': 'port_latitude',\n",
    "    'longitude': 'port_longitude'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Preprocessing \n",
    "\n",
    "Handling default values, outliers, and missing data was essential for improving data consistency and accuracy.\n",
    "<br><br>\n",
    "Replacing Default and Outlier Values: AIS data uses certain default values to indicate unavailable or invalid measurements. For example, cog (course over ground) values are defaulted to 360 when not available. We replaced these default values with NaN, which allowed the model to ignore invalid values rather than treating them as valid data points but without any useful meaning.\n",
    "<br>For cog: Replaced 360 with NaN and removed values above 360.\n",
    "<br>For sog (speed over ground): Replaced 1023 with NaN, as this default represents unavailable data.\n",
    "<br>For rot (rate of turn): Replaced 128 with NaN, indicating missing values. Additionally, values of +127 and -127 signify an uncertain rate of turn. We replaced these values with extreme values (200 and -200, respectively) and added an uncertain_rot flag to mark these rows.\n",
    "<br>For heading: Replaced 511 with NaN, which indicates an unavailable heading measurement.\n",
    "This preprocessing step ensures that only valid valued are being taken into account, and helps our model to perform better without biased values.\n",
    "\n",
    "<br>Adding Flags: we added an uncertain_rot flag to identify rows where rot values were uncertain (200 or -200). Additionally, we created an isMoored flag to denote when vessels were moored, derived from the navstat variable (navstat = 5 indicates a moored vessel). This feature helped identify vessels that were stationary, which could influence movement-based analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Replacing default with Nan bacause too close to valid values, eliminate non valid values\n",
    "    df['cog'] = df['cog'].replace(360, np.nan)\n",
    "    df = df[(df['cog'] <= 360) | (df['cog'].isna())]\n",
    "\n",
    "    # Replacing default with Nan bacause too close to valid values\n",
    "    df['sog'] = df['sog'].replace(1023, np.nan)\n",
    "\n",
    "    # Replacing default with Nan bacause too close to valid values\n",
    "    # Changing uncertain values to bigger number to be further away from sample pool\n",
    "    # Adding uncertainty flag\n",
    "    df['rot'] = df['rot'].replace(128, np.nan)\n",
    "    df['rot'] = df['rot'].replace({127: 200, -127: -200})\n",
    "    df['uncertain_rot'] = np.where(df['rot'].isin([200, -200]), 1, 0)\n",
    "\n",
    "    # Replacing default value with NaN to not get taken in consideration by regression\n",
    "    df['heading'] = df['heading'].replace(511, np.nan)\n",
    "\n",
    "    # Adding a \"is moored?\" flag\n",
    "    df['isMoored'] = (df['navstat'] == 5).astype(int)   \n",
    "\n",
    "    # Time Handling \n",
    "    df['time'] = pd.to_datetime(df['time'], errors='coerce').dt.tz_localize('UTC')\n",
    "    # Standardize eta\n",
    "    df['etaRaw'] = df['etaRaw'].fillna(0)\n",
    "    df['etaRaw'] = df['etaRaw'].apply(lambda x: f\"{2024}-{x}\")\n",
    "    df['etaRaw'] = pd.to_datetime(df['etaRaw'], errors='coerce').dt.tz_localize('UTC')\n",
    "    df.rename(columns={'etaRaw': 'etaStd'}, inplace=True)\n",
    "    # Handle first month of the years ETA year to be 2023\n",
    "    df['etaStd'] = df.apply(lambda row: row['etaStd'].replace(year=row['etaStd'].year - 1)\n",
    "                            if row['etaStd'].month in [11, 12] and row['time'].month in [1, 2] \n",
    "                            else row['etaStd'], axis=1) \n",
    "\n",
    "    # FEATURE ENGINEERING\n",
    "    # Get day of the week \n",
    "    df['dayofweek'] = df['time'].dt.dayofweek\n",
    "    df['eta_dayoftheweek'] = df['etaStd'].dt.dayofweek \n",
    "    # Converts time and eta to seconds and add difference between the two\n",
    "    df['time_seq'] = df['time'].astype(int) / 10**9  \n",
    "    df['eta_seq'] = df['etaStd'].astype(int) / 10**9 \n",
    "    df['estimated_time_left'] = df['time_seq'] - df['eta_seq']\n",
    "    # Add port coordinates\n",
    "    df = pd.merge(df, ports, on='portId', how='left')\n",
    "    # Add a three days rolling average for the AIS data \n",
    "    df['sog_mean'] = df.groupby('vesselId', group_keys=False).apply(\n",
    "    lambda x: x.sort_values('time').rolling('3D', on='time')['sog'].mean())\n",
    "    df['cog_mean'] = df.groupby('vesselId', group_keys=False).apply(\n",
    "    lambda x: x.sort_values('time').rolling('3D', on='time')['cog'].mean())\n",
    "    df['rot_mean'] = df.groupby('vesselId', group_keys=False).apply(\n",
    "    lambda x: x.sort_values('time').rolling('3D', on='time')['rot'].mean())\n",
    "    df['heading_mean'] = df.groupby('vesselId', group_keys=False).apply(\n",
    "    lambda x: x.sort_values('time').rolling('3D', on='time')['heading'].mean())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestamp Handling and Date Features\n",
    "Time and ETA Standardization: Both time and etaRaw columns were converted to standardized datetime formats, in order to make more accurate time-based calculations.\n",
    "\n",
    "time was converted to a timezone-aware UTC datetime.\n",
    "\n",
    "etaRaw was standardized to etaStd, with missing values filled as 0. The format was modified to incorporate the current year (2024-) for ease of handling.\n",
    "<br>Adjusting ETA Across Years: For vessels scheduled to arrive early in the year (January or February) but reporting etaRaw in November or December, we adjusted the year of etaStd to the previous year (2023). This adjustment avoided errors in estimated time calculations by aligning cross-year arrivals with correct temporal references.\n",
    "\n",
    "Creating Derived Time Features: To capture weekly trends in vessel activity, we created two new features, dayofweek and eta_dayoftheweek, representing the weekday for both the time and etaStd columns. This step allowed us to capture weekly patterns that may influence vessel schedules and movement behaviors.\n",
    "\n",
    "Converting Time to Seconds and Calculating Differences: The time and etaStd columns were converted to Unix timestamps (time_seq and eta_seq), representing the seconds since the Unix epoch. We then computed estimated_time_left as the difference between these two features, representing the remaining time for a vessel to reach its destination.\n",
    "This feature, estimated_time_left, provides an estimated arrival time which is useful for making predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Port Coordinates: The next step was to add port coordinates to the AIS dataset. I merged the AIS dataset with ports data on the portId column, using a left join to ensure that each vessel’s record retained the port’s latitude and longitude (port_latitude, port_longitude).\n",
    "Including port location data is essential for geospatial analysis, providing context for vessel proximity to ports and supporting models that incorporate spatial features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To smooth out short-term fluctuations and capture broader trends, we applied a 3-day rolling average to key navigation variables: sog (speed over ground), cog (course over ground), rot (rate of turn), and heading. These rolling averages were computed individually for each vessel by grouping data by vesselId and sorting by time.\n",
    "For instance, sog_mean represents the average speed of a vessel over a 3-day window. By doing this, we create a more stable trend for each vessel's movement over time, making easier for our model to learn and predict consistent behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
