{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c158e653",
   "metadata": {},
   "source": [
    "[120]Magna Graecia\\\n",
    "Sergio Enrico Pisoni 132855\\\n",
    "Sofia Papaioannou 132898\\\n",
    "Lefteris Verouchis 132873"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d379a",
   "metadata": {},
   "source": [
    "# SHORT NOTEBOOK RESULT n.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5e0442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd \n",
    "import geopandas as gpd \n",
    "import numpy as np\n",
    "from calendar import monthrange\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from shapely.ops import nearest_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9dbc41",
   "metadata": {},
   "source": [
    "## Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04a11164",
   "metadata": {},
   "outputs": [],
   "source": [
    "ports = pd.read_csv('ports.csv', sep ='|')\n",
    "# Clean port data\n",
    "ports = ports.drop(columns=['name', 'portLocation', 'UN_LOCODE', 'countryName', 'ISO'], errors='ignore')\n",
    "# Rename latitude and longitude to distinguish them\n",
    "ports = ports.rename(columns={\n",
    "    'latitude': 'port_latitude',\n",
    "    'longitude': 'port_longitude'\n",
    "})\n",
    "\n",
    "def preprocess(df):\n",
    "    # Replacing default with Nan bacause too close to valid values, eliminate non valid values\n",
    "    df['cog'] = df['cog'].replace(360, np.nan)\n",
    "    df = df[(df['cog'] <= 360) | (df['cog'].isna())]\n",
    "\n",
    "    # Replacing default with Nan bacause too close to valid values\n",
    "    df['sog'] = df['sog'].replace(1023, np.nan)\n",
    "\n",
    "    # Replacing default with Nan bacause too close to valid values\n",
    "    # Changing uncertain values to bigger number to be further away from sample pool\n",
    "    # Adding uncertainty flag\n",
    "    df['rot'] = df['rot'].replace(128, np.nan)\n",
    "    df['rot'] = df['rot'].replace({127: 200, -127: -200})\n",
    "    df['uncertain_rot'] = np.where(df['rot'].isin([200, -200]), 1, 0)\n",
    "\n",
    "    # Replacing default value with NaN to not get taken in consideration by regression\n",
    "    df['heading'] = df['heading'].replace(511, np.nan)\n",
    "\n",
    "    # Adding a \"is moored?\" flag\n",
    "    df['isMoored'] = (df['navstat'] == 5).astype(int)   \n",
    "\n",
    "    # Time Handling \n",
    "    df['time'] = pd.to_datetime(df['time'], errors='coerce').dt.tz_localize('UTC')\n",
    "    # Standardize eta\n",
    "    df['etaRaw'] = df['etaRaw'].fillna(0)\n",
    "    df['etaRaw'] = df['etaRaw'].apply(lambda x: f\"{2024}-{x}\")\n",
    "    df['etaRaw'] = pd.to_datetime(df['etaRaw'], errors='coerce').dt.tz_localize('UTC')\n",
    "    df.rename(columns={'etaRaw': 'etaStd'}, inplace=True)\n",
    "    # Handle first month of the years ETA year to be 2023\n",
    "    df['etaStd'] = df.apply(lambda row: row['etaStd'].replace(year=row['etaStd'].year - 1)\n",
    "                            if row['etaStd'].month in [11, 12] and row['time'].month in [1, 2] \n",
    "                            else row['etaStd'], axis=1) \n",
    "    \n",
    "\n",
    "    # FEATURE ENGINEERING\n",
    "    # Get day of the week \n",
    "    df['dayofweek'] = df['time'].dt.dayofweek\n",
    "    df['eta_dayoftheweek'] = df['etaStd'].dt.dayofweek \n",
    "    # Converts time and eta to seconds and add difference between the two\n",
    "    df['time_seq'] = df['time'].astype(int) / 10**9  \n",
    "    df['eta_seq'] = df['etaStd'].astype(int) / 10**9 \n",
    "    df['estimated_time_left'] = df['time_seq'] - df['eta_seq']\n",
    "    # Add port coordinates\n",
    "    df = pd.merge(df, ports, on='portId', how='left')\n",
    "    # Add a three days rolling average for the AIS data \n",
    "    df['sog_mean'] = df.groupby('vesselId', group_keys=False).apply(\n",
    "    lambda x: x.sort_values('time').rolling('3D', on='time')['sog'].mean())\n",
    "    df['cog_mean'] = df.groupby('vesselId', group_keys=False).apply(\n",
    "    lambda x: x.sort_values('time').rolling('3D', on='time')['cog'].mean())\n",
    "    df['rot_mean'] = df.groupby('vesselId', group_keys=False).apply(\n",
    "    lambda x: x.sort_values('time').rolling('3D', on='time')['rot'].mean())\n",
    "    df['heading_mean'] = df.groupby('vesselId', group_keys=False).apply(\n",
    "    lambda x: x.sort_values('time').rolling('3D', on='time')['heading'].mean())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b5c45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_set(df, steps):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "    \n",
    "    # FEATURE ENGINEERING\n",
    "    # Vessels last collenction data\n",
    "    df_copy['latitude_lag'] = df_copy.groupby('vesselId')['latitude'].shift(steps)\n",
    "    df_copy['longitude_lag'] = df_copy.groupby('vesselId')['longitude'].shift(steps)\n",
    "    df_copy['port_longitude_lag'] = df_copy.groupby('vesselId')['port_longitude'].shift(steps)\n",
    "    df_copy['port_latitude_lag'] = df_copy.groupby('vesselId')['port_latitude'].shift(steps)\n",
    "    df_copy['isMoored_lag'] = df_copy.groupby('vesselId')['isMoored'].shift(steps)\n",
    "    df_copy['sog_lag'] = df_copy.groupby('vesselId')['sog'].shift(steps)\n",
    "    df_copy['sog_mean_lag'] = df_copy.groupby('vesselId')['sog_mean'].shift(steps)\n",
    "    df_copy['cog_lag'] = df_copy.groupby('vesselId')['cog'].shift(steps)\n",
    "    df_copy['cog_mean_lag'] = df_copy.groupby('vesselId')['cog_mean'].shift(steps)     \n",
    "    df_copy['rot_lag'] = df_copy.groupby('vesselId')['rot'].shift(steps) \n",
    "    df_copy['rot_mean_lag'] = df_copy.groupby('vesselId')['rot_mean'].shift(steps)\n",
    "    df_copy['uncertain_rot_lag'] = df_copy.groupby('vesselId')['uncertain_rot'].shift(steps) \n",
    "    df_copy['heading_lag'] = df_copy.groupby('vesselId')['heading'].shift(steps)\n",
    "    df_copy['heading_mean_lag'] = df_copy.groupby('vesselId')['heading_mean'].shift(steps)  \n",
    "    df_copy['dayofweek_lag'] = df_copy.groupby('vesselId')['dayofweek'].shift(steps)\n",
    "    # Time since last data collection\n",
    "    df_copy['time_diff'] = df_copy.groupby('vesselId')['time'].diff(steps)\n",
    "    df_copy['time_diff_seconds'] = df_copy['time_diff'].dt.total_seconds()\n",
    "    # Time to eta\n",
    "    df_copy['estimated_time_left_lag'] = df_copy.groupby('vesselId')['estimated_time_left'].shift(steps)\n",
    "    df_copy.dropna(subset=['time_diff'], inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5033b9",
   "metadata": {},
   "source": [
    "## Process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce5d4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "known_positions = pd.read_csv('ais_train.csv', sep ='|')  # Replace with your dataset\n",
    "test = pd.read_csv('ais_test.csv', sep =',')\n",
    "# Preprocess train\n",
    "known_positions = preprocess(known_positions)\n",
    "train = known_positions.copy()\n",
    "# Create training sets with variable time difference\n",
    "time_intervals = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 44, 48, 52, 56, 60, 64, 68, 72] #until 88hrs intervals\n",
    "train_sets = {}\n",
    "for interval in time_intervals:\n",
    "    train_sets[f'train{interval}'] = make_training_set(train, interval)\n",
    "\n",
    "train = pd.concat(list(train_sets.values()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ef1c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['portId'] = pd.Categorical(train['portId']).codes\n",
    "# Encoding test and train vesselID with the same encoder \n",
    "unique_vessel_ids = pd.concat([known_positions['vesselId'], test['vesselId']]).unique()\n",
    "vessel_encoder = LabelEncoder()\n",
    "vessel_encoder.fit(unique_vessel_ids)\n",
    "# Transform the vesselId column in train\n",
    "train['vesselId'] = vessel_encoder.transform(train['vesselId'])\n",
    "\n",
    "# Clean missing data\n",
    "train = train.dropna(subset=['latitude', 'longitude', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b87688",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[[\n",
    "    'vesselId', #try\n",
    "    'latitude_lag',\n",
    "    'longitude_lag',\n",
    "    'port_latitude_lag',\n",
    "    'port_longitude_lag',\n",
    "    'isMoored_lag',\n",
    "    'sog_lag',\n",
    "    'sog_mean_lag',\n",
    "    'cog_lag',\n",
    "    'cog_mean_lag',\n",
    "    'rot_lag',\n",
    "    'rot_mean_lag',\n",
    "    'uncertain_rot_lag',\n",
    "    'heading_lag',\n",
    "    'heading_mean_lag',\n",
    "    'dayofweek_lag',\n",
    "    'time_diff_seconds',\n",
    "    'estimated_time_left_lag',\n",
    "]]\n",
    "y = train[['latitude', 'longitude']]\n",
    "\n",
    "X = X.apply(pd.to_numeric, errors='coerce') # Not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895c3b4",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d4c24f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.24196263261990883,\n",
       "                                            max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=9,\n",
       "                                            max_leaves=None, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=185, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=42, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.24196263261990883,\n",
       "                                            max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=9,\n",
       "                                            max_leaves=None, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=185, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=42, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.24196263261990883,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=185, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.24196263261990883,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=185, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.24196263261990883,\n",
       "                                            max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=9,\n",
       "                                            max_leaves=None, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=185, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=42, ...))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "# Train the model\n",
    "base_model = xgb.XGBRegressor(\n",
    "    learning_rate=0.24196263261990883,\n",
    "    max_depth=9,\n",
    "    min_child_weight=1,\n",
    "    n_estimators=185,\n",
    "    subsample=0.9136916108674354,\n",
    "    random_state=42\n",
    ")\n",
    "model = MultiOutputRegressor(base_model)\n",
    "model.fit(X_scaled, y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af9d9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['time'] = pd.to_datetime(test['time'], errors='coerce').dt.tz_localize('UTC')\n",
    "test['vesselId'] = vessel_encoder.transform(test['vesselId'])\n",
    "known_positions['vesselId'] = vessel_encoder.transform(known_positions['vesselId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b48202bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prediction_data(test_df, known_positions):\n",
    "    # Get last known position for each vessel before the test time\n",
    "    predictions_data = []\n",
    "    \n",
    "    # Group by vessel ID to avoid repeated processing\n",
    "    vessel_histories = dict(tuple(known_positions.groupby('vesselId')))\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        vessel_history = vessel_histories[row['vesselId']]\n",
    "        # Get last position before test time\n",
    "        last_detection = vessel_history[vessel_history['time'] < row['time']].iloc[-1]\n",
    "        \n",
    "        predictions_data.append({\n",
    "            'vesselId': last_detection['vesselId'],\n",
    "            'latitude_lag': last_detection['latitude'],\n",
    "            'longitude_lag': last_detection['longitude'],\n",
    "            'port_latitude_lag': last_detection['port_latitude'],\n",
    "            'port_longitude_lag': last_detection['port_longitude'],\n",
    "            'isMoored_lag': last_detection['isMoored'],\n",
    "            'sog_lag': last_detection['sog'],\n",
    "            'sog_mean_lag': last_detection['sog_mean'],\n",
    "            'cog_lag': last_detection['cog'],\n",
    "            'cog_mean_lag': last_detection['cog_mean'],\n",
    "            'rot_lag': last_detection['rot'],\n",
    "            'rot_mean_lag': last_detection['rot_mean'],\n",
    "            'uncertain_rot_lag': last_detection['uncertain_rot'],\n",
    "            'heading_lag': last_detection['heading'],\n",
    "            'heading_mean_lag': last_detection['heading_mean'],\n",
    "            'dayofweek_lag': last_detection['dayofweek'],\n",
    "            'time_diff_seconds': (pd.to_datetime(row['time']) - last_detection['time']).total_seconds(),\n",
    "            'estimated_time_left_lag': last_detection['estimated_time_left'],\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(predictions_data)\n",
    "\n",
    "# Prepare prediction Data\n",
    "input_df = prepare_prediction_data(test, known_positions)\n",
    "# Scale it \n",
    "input_df_scaled = scaler_X.transform(input_df)\n",
    "# Make predictions for all rows at once\n",
    "predictions_scaled = model.predict(input_df_scaled)\n",
    "predictions = scaler_y.inverse_transform(predictions_scaled)\n",
    "# Create results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'ID': test.index,\n",
    "    'longitude_predicted': predictions[:, 1],\n",
    "    'latitude_predicted': predictions[:, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c382b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('no_postproc_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805fd90",
   "metadata": {},
   "source": [
    "## Post processing\n",
    "Move all predictions to sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "181234c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('ais_test.csv', sep=',') # reset test df\n",
    "test = test.drop(columns=['scaling_factor']) \n",
    "merged = pd.merge(results, test, on='ID', how='left')\n",
    "merged['time'] = pd.to_datetime(merged['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff9cfacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ocean and land shape files\n",
    "land_world = gpd.read_file('ne_10m_land/ne_10m_land.shp').to_crs(4326)\n",
    "ocean_world = gpd.read_file('ne_10m_ocean/ne_10m_ocean.shp').to_crs(4326)\n",
    "# Make Geo Data Frame\n",
    "gdf = gpd.GeoDataFrame(merged, geometry=gpd.points_from_xy(merged['longitude_predicted'], merged['latitude_predicted'], crs=\"EPSG:4326\"))\n",
    "# Check if point is on land\n",
    "points_on_land = gpd.sjoin(gdf, land_world, how=\"inner\", predicate=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5093a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get closest points in sea\n",
    "closest_longitudes = []\n",
    "closest_latitudes = []\n",
    "for _, row in points_on_land.iterrows():\n",
    "    closest_point, _ = nearest_points(ocean_world['geometry'], row['geometry'])\n",
    "    closest_longitudes.append(closest_point.x)\n",
    "    closest_latitudes.append(closest_point.y)\n",
    "points_on_land['closest_longitude'] = closest_longitudes\n",
    "points_on_land['closest_latitude'] = closest_latitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f002286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_k/_j2m440s1cdcpmdx7hff9q0r0000gn/T/ipykernel_24704/3106212199.py:2: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  gdf.loc[points_on_land.index, 'longitude_predicted'] = points_on_land['closest_longitude'].astype(float)\n",
      "/var/folders/_k/_j2m440s1cdcpmdx7hff9q0r0000gn/T/ipykernel_24704/3106212199.py:3: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  gdf.loc[points_on_land.index, 'latitude_predicted'] = points_on_land['closest_latitude'].astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Update predictions\n",
    "gdf.loc[points_on_land.index, 'longitude_predicted'] = points_on_land['closest_longitude'].astype(float)\n",
    "gdf.loc[points_on_land.index, 'latitude_predicted'] = points_on_land['closest_latitude'].astype(float)\n",
    "gdf = gdf.drop(columns=['vesselId', 'time', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a63affb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>longitude_predicted</th>\n",
       "      <th>latitude_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-81.061531</td>\n",
       "      <td>31.150185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>119.163216</td>\n",
       "      <td>16.067413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.278606</td>\n",
       "      <td>38.422421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>172.999008</td>\n",
       "      <td>-43.415024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-6.478345</td>\n",
       "      <td>48.567219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  longitude_predicted  latitude_predicted\n",
       "0   0           -81.061531           31.150185\n",
       "1   1           119.163216           16.067413\n",
       "2   2            11.278606           38.422421\n",
       "3   3           172.999008          -43.415024\n",
       "4   4            -6.478345           48.567219"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf00aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_csv('result_n2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
